


yangjie_rich_pretrain_unigram_path = '/home/ghost/NLP/corpus/embedding/chinese/lexicon/gigaword_chn.all.a2b.uni.11k.50d.vec'
yangjie_rich_pretrain_bigram_path = '/home/ghost/NLP/corpus/embedding/chinese/lexicon/gigaword_chn.all.a2b.bi.3987k.50d.vec'
yangjie_rich_pretrain_word_path = '/home/ghost/NLP/corpus/embedding/chinese/lexicon/ctb.704k.50d.vec'
yangjie_rich_pretrain_char_and_word_path = '/home/ghost/NLP/corpus/embedding/chinese/lexicon/yangjie_word_char_mix.txt'
lk_word_path = '/home/ghost/NLP/corpus/embedding/chinese/lexicon/sgns_merge_word.1293k.300d.vec'
# lk_word_path_2 = '/remote-home/xnli/data/pretrain/chinese/sgns.merge.word_2'

ontonote4ner_cn_path = '../data/ontonotes4'
msra_ner_cn_path = '../data/msra'
resume_ner_path = '../data/resume'
weibo_ner_path = '../data/weibo'
policy_ner_path = '../data/policy'

bert_chinese_path = '/home/ghost/NLP/corpus/transformers/chinese-bert-wwm-ext'

# yangjie_rich_pretrain_unigram_path = '{}/gigaword_chn.all.a2b.uni.ite50.vec'
# yangjie_rich_pretrain_bigram_path = '{}/gigaword_chn.all.a2b.bi.ite50.vec'
# yangjie_rich_pretrain_word_path = '{}/ctb.50d.vec'
#
# # this path is for the output of preprocessing
# yangjie_rich_pretrain_char_and_word_path = '{}/yangjie_word_char_mix.txt'
#
#
#
# ontonote4ner_cn_path = '{}/OntoNote4NER'
# msra_ner_cn_path = '{}/MSRANER'
# resume_ner_path = '{}/ResumeNER'
# weibo_ner_path = '{}/WeiboNER'
